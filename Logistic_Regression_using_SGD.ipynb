{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2S-uFqwSvmg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUxLkBjISvmr"
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xexp5GYNSvmz",
        "outputId": "3e6d8ea2-fd83-426a-c90c-8b9b48a8cb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vJVc_KSvm9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pKAn1-ASvm_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97pFTgrSvnE"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jykLIXZNSvnJ",
        "outputId": "e3810fee-0e20-4401-dd25-0f15bbd6d7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "print(y_train)\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-M6oXASvnO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShoMeocSvnP"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm6wi8L2SvnU"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term.\n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su9e8fRLSvno"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcz5_UqCSvnq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOBvEchCSvnr"
      },
      "source": [
        "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbn61rrXSvnt"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bA5yR3Svnv"
      },
      "source": [
        "- Load the datasets(train and test) into the respective arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7183hFBSvnv"
      },
      "source": [
        "- Initialize the weight_vector and intercept term randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdLeFU0USvnx"
      },
      "source": [
        "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEVtAlO1Svny"
      },
      "source": [
        "- for each epoch:\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
        "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
        "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmRH4UpSvny"
      },
      "source": [
        "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbZf9p5gSvn1"
      },
      "source": [
        "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWlcwsMsqD-5"
      },
      "source": [
        "y_train= np.array([y_train])\n",
        "y_test= np.array([y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw909DzvqEcl"
      },
      "source": [
        "x_train = x_train.T\n",
        "x_test= x_test.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCtyxd3-qEpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "745d85c3-1231-4a1b-d4f7-0111210b384e"
      },
      "source": [
        "lenw= x_train.shape[0]\n",
        "w= np.random.randn(1,lenw) # weight vectors #-----> 1xn, X ----> nxm\n",
        "b= 0                       #  bias value\n",
        "m= len(x_train)\n",
        "print(w.shape)\n",
        "def predict(X,w,b):\n",
        "  y_cap= 1/(1+np.exp(-(np.dot(w,X)+ b))) # -----> 1xm\n",
        "  return y_cap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpz8X5DMSvn2"
      },
      "source": [
        "w = np.zeros_like(X_train[0])\n",
        "b = 0\n",
        "eta0  = 0.0001\n",
        "alpha = 0.0001\n",
        "N = len(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Y5kVscSvn5"
      },
      "source": [
        "# write your code to implement SGD as per the above instructions\n",
        "# please choose the number of iternations on your own"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yy8jWaa7Svn_"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48gx6wQKSvoE"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}