{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDRNrY2NCXf"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
        "\n",
        "2. Code the model to classify data like below image\n",
        "\n",
        "<img src='https://i.imgur.com/33ptOFy.png'>\n",
        "\n",
        "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
        "\n",
        "4. Save your model at every epoch if your validation accuracy is improved from previous epoch.\n",
        "\n",
        "5. you have to decay learning based on below conditions\n",
        "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
        "               learning rate by 10%.\n",
        "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
        "        \n",
        "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training.\n",
        "\n",
        "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
        "\n",
        "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "9. use cross entropy as loss function\n",
        "\n",
        "10. Try the architecture params as given below.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w41Y3TFENCXk"
      },
      "source": [
        "<pre>\n",
        "<b>Model-1</b>\n",
        "<pre>\n",
        "1. Use tanh as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-2</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-3</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use he_uniform() as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-4</b>\n",
        "<pre>\n",
        "1. Try with any values to get better accuracy/f1 score.  \n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ9uR1_RcXDX"
      },
      "source": [
        "import tensorflow as tf\n",
        "#enabled to get instant output. if you don't need, you can use session concept which was dicussed in lecture videos.\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VBQqdqbbvo3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWmsfFJbv-U"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3nXQTBlb1ZI",
        "outputId": "a1f39ec3-83c1-49fd-ddcd-e4a44a53a280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i-Hhhaqb3Ru"
      },
      "source": [
        "from tensorflow.keras.layers import Dense,Input,Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiIMJszNb6gA"
      },
      "source": [
        "class Callback(object):\n",
        "\n",
        "    \"\"\"Abstract base class used to build new callbacks.\n",
        "      Attributes:\n",
        "          params: dict. Training parameters\n",
        "              (eg. verbosity, batch size, number of epochs...).\n",
        "          model: instance of `keras.models.Model`.\n",
        "              Reference of the model being trained.\n",
        "          validation_data: Deprecated. Do not use.\n",
        "      The `logs` dictionary that callback methods\n",
        "      take as argument will contain keys for quantities relevant to\n",
        "      the current batch or epoch.\n",
        "      Currently, the `.fit()` method of the `Model` class\n",
        "      will include the following quantities in the `logs` that\n",
        "      it passes to its callbacks:\n",
        "          on_epoch_end: logs include `acc` and `loss`, and\n",
        "          optionally include `val_loss`\n",
        "          (if validation is enabled in `fit`), and `val_acc`\n",
        "          (if validation and accuracy monitoring are enabled).\n",
        "          on_batch_begin: logs include `size`,\n",
        "          the number of samples in the current batch.\n",
        "          on_batch_end: logs include `loss`, and optionally `acc`\n",
        "            (if accuracy monitoring is enabled).\n",
        "      \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.validation_data = None\n",
        "        self.model = None\n",
        "        # Whether this Callback should only run on the chief worker in a\n",
        "        # Multi-Worker setting.\n",
        "        # TODO(omalleyt): Make this attr public once solution is stable.\n",
        "        self._chief_worker_only = None\n",
        "\n",
        "    def set_params(self, params):\n",
        "        self.params = params\n",
        "\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        \"\"\"Called at the start of an epoch.\n",
        "        Subclasses should override for any actions to run. This function should only\n",
        "        be called during TRAIN mode.\n",
        "        Arguments:\n",
        "            epoch: integer, index of epoch.\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\"Called at the end of an epoch.\n",
        "        Subclasses should override for any actions to run. This function should only\n",
        "        be called during TRAIN mode.\n",
        "        Arguments:\n",
        "            epoch: integer, index of epoch.\n",
        "            logs: dict, metric results for this training epoch, and for the\n",
        "              validation epoch if validation is performed. Validation result keys\n",
        "              are prefixed with `val_`.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a training batch in `fit` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "              number and the size of the batch.\n",
        "        \"\"\"\n",
        "        # For backwards compatibility.\n",
        "        self.on_batch_begin(batch, logs=logs)\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a training batch in `fit` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "        # For backwards compatibility.\n",
        "        self.on_batch_end(batch, logs=logs)\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n",
        "        Also called at the beginning of a validation batch in the `fit`\n",
        "        methods, if validation data is provided.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "                  number and the size of the batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a batch in `evaluate` methods.\n",
        "        Also called at the end of a validation batch in the `fit`\n",
        "        methods, if validation data is provided.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a batch in `predict` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "                  number and the size of the batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a batch in `predict` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of training.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "                  but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        \"\"\"Called at the end of training.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "                  but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of evaluation or validation.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        \"\"\"Called at the end of evaluation or validation.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of prediction.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        \"\"\"Called at the end of prediction.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyFRTlddjTJa"
      },
      "source": [
        "Micro F1 score and AUC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdt3q-9Y5vNM",
        "outputId": "e86fb17d-0864-4a76-f0b5-cb50af01c965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data=(X_test,Y_test),  interval=1):\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "        y_pred_train = self.model.predict(self.X_val)\n",
        "        roc_train = roc_auc_score(self.y_val, y_pred_train)\n",
        "        y_pred_val = self.model.predict(self.X_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val)))\n",
        "        val_targ = self.y_val\n",
        "        val_predict=np.argmax(val_predict, axis=1)\n",
        "        val_targ=np.argmax(val_targ, axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average= 'micro')\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"\\rroc-auc_train: %s - roc-auc_val: %s- f1-train_score: %s - f1_val: %s \" %(str(round(roc_train,4)),str(round(roc_val,4)),str(round(_val_f1,4)),str(round(_val_recall,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "input_layer = Input(shape=(784,))\n",
        "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer2 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer3 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer4 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer5 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "history_own = Metrics()\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test), batch_size=16, callbacks=[history_own])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "roc-auc_train: 0.9216 - roc-auc_val: 0.9216- f1-train_score: 0.6211 - f1_val: 0.6211                                                                                                     \n",
            "60000/60000 [==============================] - 10s 165us/sample - loss: 1.3916 - val_loss: 1.1099\n",
            "Epoch 2/3\n",
            "roc-auc_train: 0.9354 - roc-auc_val: 0.9354- f1-train_score: 0.6263 - f1_val: 0.6263                                                                                                     \n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 1.0978 - val_loss: 1.0448\n",
            "Epoch 3/3\n",
            "roc-auc_train: 0.9503 - roc-auc_val: 0.9503- f1-train_score: 0.7048 - f1_val: 0.7048                                                                                                     \n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.9938 - val_loss: 0.8732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08f7260e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avKIXak6efR",
        "outputId": "2477af40-24d7-46ba-f4ce-7deb7e1ea9d0",
        "colab": {
          "resources": {
            "http://localhost:6006/": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTAwIChJbnRlcm5hbCBTZXJ2ZXIgRXJyb3IpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDAuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1461"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 500,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtmz5trRjjLh"
      },
      "source": [
        "Model-check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5VNxE76j9x"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t2za4bT4C71",
        "outputId": "fc4f198e-e851-4f25-a6c7-c05ccc526e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(784,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "#output layer\n",
        "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',  verbose=1,save_weights_only=False, save_best_only=False , mode='max')\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 1.3210 - acc: 0.5356\n",
            "Epoch 00001: saving model to weights-improvement-01-0.6218.hdf5\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 1.3209 - acc: 0.5356 - val_loss: 1.1057 - val_acc: 0.6218\n",
            "Epoch 2/3\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 1.0632 - acc: 0.6309\n",
            "Epoch 00002: saving model to weights-improvement-02-0.7006.hdf5\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 1.0630 - acc: 0.6309 - val_loss: 0.9194 - val_acc: 0.7006\n",
            "Epoch 3/3\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.9391 - acc: 0.6811\n",
            "Epoch 00003: saving model to weights-improvement-03-0.6900.hdf5\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.9391 - acc: 0.6811 - val_loss: 0.9043 - val_acc: 0.6900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08f2ade550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbfHewdj8k2n"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NPMpvl1k3Iu"
      },
      "source": [
        "Decaying learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHKXPdyGyHxp"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfaC4so_jw12"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEuy5uCByNxT",
        "outputId": "2c1db9d1-2822-4834-8cc9-8e56f7df1e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(784,))\n",
        "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer2 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer3 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer4 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer5 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n",
        "\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0, patience=1, min_lr=0.1)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 2.3617 - acc: 0.2257 - val_loss: 2.5603 - val_acc: 0.1447\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 2.3666 - acc: 0.2274 - val_loss: 2.2248 - val_acc: 0.2609\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 2.2281 - acc: 0.2543 - val_loss: 2.2414 - val_acc: 0.3087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08f1e7f048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg4ZtFHnk9JN"
      },
      "source": [
        "Terminate on nan:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXaD2NdDyN8D"
      },
      "source": [
        "from tensorflow.keras.callbacks import TerminateOnNaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSlm30-OyOAQ",
        "outputId": "1cf89fc8-d857-4825-d82d-94cf920cabd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Input layer\n",
        "input_layer = Input(shape=(784,))\n",
        "#Dense hidden layer\n",
        "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer2 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer3 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer4 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer5 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n",
        "\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "\n",
        "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[terminate ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 2.2554 - acc: 0.2228 - val_loss: 2.6960 - val_acc: 0.1801\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 2.1903 - acc: 0.2330 - val_loss: 2.2899 - val_acc: 0.2354\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 2.1233 - acc: 0.2546 - val_loss: 2.5124 - val_acc: 0.1843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08f1cfdb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZOecV_wlJ4m"
      },
      "source": [
        "EArlystopping-stopping if val_acc is not incerasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy4XYeshliaH",
        "outputId": "5b86c1f8-0617-4da6-9c65-13406cdc95dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "input_layer = Input(shape=(784,))\n",
        "\n",
        "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer2 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer3 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer4 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "layer5 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
        "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer5)\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "callback12 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[callback12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 2.2861 - acc: 0.2512 - val_loss: 2.0577 - val_acc: 0.3033\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 2.3167 - acc: 0.2459 - val_loss: 2.3681 - val_acc: 0.2334\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 2.1063 - acc: 0.3160 - val_loss: 1.9739 - val_acc: 0.3184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08eba07a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLiNSoMCpRUA"
      },
      "source": [
        "MODEL-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaeHc6IC7mTh",
        "outputId": "c1868031-dfe5-4d9d-8f2a-fa200c802cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "input_layer = Input(shape=(784,))\n",
        "layer1 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "layer2 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "layer3 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "layer4 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "layer5 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(input_layer)\n",
        "output = Dense(10,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1))(layer5)\n",
        "model = Model(inputs=input_layer,outputs=output)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(0.1),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 13.7243 - acc: 0.1000 - val_loss: 13.7243 - val_acc: 0.1000\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 13.7243 - acc: 0.1000 - val_loss: 13.7243 - val_acc: 0.1000\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 13.7243 - acc: 0.1000 - val_loss: 13.7243 - val_acc: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08eb932080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT1a0j1CXLMc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2m2JG1rlhnh",
        "outputId": "a89dde35-a877-49c4-95a5-62d422e9ea72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}