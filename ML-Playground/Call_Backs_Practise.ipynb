{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDRNrY2NCXf"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
        "\n",
        "2. Code the model to classify data like below image\n",
        "\n",
        "<img src='https://i.imgur.com/33ptOFy.png'>\n",
        "\n",
        "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
        "\n",
        "4. Save your model at every epoch if your validation accuracy is improved from previous epoch.\n",
        "\n",
        "5. you have to decay learning based on below conditions\n",
        "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
        "               learning rate by 10%.\n",
        "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
        "        \n",
        "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training.\n",
        "\n",
        "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
        "\n",
        "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "9. use cross entropy as loss function\n",
        "\n",
        "10. Try the architecture params as given below.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w41Y3TFENCXk"
      },
      "source": [
        "<pre>\n",
        "<b>Model-1</b>\n",
        "<pre>\n",
        "1. Use tanh as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-2</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-3</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use he_uniform() as initilizer.\n",
        "3. Analyze your output and training process.\n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-4</b>\n",
        "<pre>\n",
        "1. Try with any values to get better accuracy/f1 score.  \n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ9uR1_RcXDX"
      },
      "source": [
        "import tensorflow as tf\n",
        "#enabled to get instant output. if you don't need, you can use session concept which was dicussed in lecture videos.\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VBQqdqbbvo3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWmsfFJbv-U",
        "outputId": "5f52c281-7e51-4b9c-fb08-9889254e9d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3nXQTBlb1ZI",
        "outputId": "7442acec-8c0f-4a03-d7c8-b10638629180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i-Hhhaqb3Ru"
      },
      "source": [
        "from tensorflow.keras.layers import Dense,Input,Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiIMJszNb6gA"
      },
      "source": [
        "class Callback(object):\n",
        "\n",
        "    \"\"\"Abstract base class used to build new callbacks.\n",
        "      Attributes:\n",
        "          params: dict. Training parameters\n",
        "              (eg. verbosity, batch size, number of epochs...).\n",
        "          model: instance of `keras.models.Model`.\n",
        "              Reference of the model being trained.\n",
        "          validation_data: Deprecated. Do not use.\n",
        "      The `logs` dictionary that callback methods\n",
        "      take as argument will contain keys for quantities relevant to\n",
        "      the current batch or epoch.\n",
        "      Currently, the `.fit()` method of the `Model` class\n",
        "      will include the following quantities in the `logs` that\n",
        "      it passes to its callbacks:\n",
        "          on_epoch_end: logs include `acc` and `loss`, and\n",
        "          optionally include `val_loss`\n",
        "          (if validation is enabled in `fit`), and `val_acc`\n",
        "          (if validation and accuracy monitoring are enabled).\n",
        "          on_batch_begin: logs include `size`,\n",
        "          the number of samples in the current batch.\n",
        "          on_batch_end: logs include `loss`, and optionally `acc`\n",
        "            (if accuracy monitoring is enabled).\n",
        "      \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.validation_data = None\n",
        "        self.model = None\n",
        "        # Whether this Callback should only run on the chief worker in a\n",
        "        # Multi-Worker setting.\n",
        "        # TODO(omalleyt): Make this attr public once solution is stable.\n",
        "        self._chief_worker_only = None\n",
        "\n",
        "    def set_params(self, params):\n",
        "        self.params = params\n",
        "\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        \"\"\"Called at the start of an epoch.\n",
        "        Subclasses should override for any actions to run. This function should only\n",
        "        be called during TRAIN mode.\n",
        "        Arguments:\n",
        "            epoch: integer, index of epoch.\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\"Called at the end of an epoch.\n",
        "        Subclasses should override for any actions to run. This function should only\n",
        "        be called during TRAIN mode.\n",
        "        Arguments:\n",
        "            epoch: integer, index of epoch.\n",
        "            logs: dict, metric results for this training epoch, and for the\n",
        "              validation epoch if validation is performed. Validation result keys\n",
        "              are prefixed with `val_`.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a training batch in `fit` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "              number and the size of the batch.\n",
        "        \"\"\"\n",
        "        # For backwards compatibility.\n",
        "        self.on_batch_begin(batch, logs=logs)\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a training batch in `fit` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "        # For backwards compatibility.\n",
        "        self.on_batch_end(batch, logs=logs)\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n",
        "        Also called at the beginning of a validation batch in the `fit`\n",
        "        methods, if validation data is provided.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "                  number and the size of the batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a batch in `evaluate` methods.\n",
        "        Also called at the end of a validation batch in the `fit`\n",
        "        methods, if validation data is provided.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"Called at the beginning of a batch in `predict` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
        "                  number and the size of the batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        \"\"\"Called at the end of a batch in `predict` methods.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            batch: integer, index of batch within the current epoch.\n",
        "            logs: dict. Metric results for this batch.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of training.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "                  but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        \"\"\"Called at the end of training.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "                  but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of evaluation or validation.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        \"\"\"Called at the end of evaluation or validation.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        \"\"\"Called at the beginning of prediction.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "        \"\"\"\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        \"\"\"Called at the end of prediction.\n",
        "        Subclasses should override for any actions to run.\n",
        "        Arguments:\n",
        "            logs: dict. Currently no data is passed to this argument for this method\n",
        "              but that may change in the future.\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyFRTlddjTJa"
      },
      "source": [
        "Micro F1 score and AUC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edbeju55VDT1"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0faUlYHasvk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVCiXSQIVDN_"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVaxGOINam7O"
      },
      "source": [
        "from tensorflow.keras.callbacks import TerminateOnNaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9lkJteyVDLf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BefpkURcVDId"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvM5yMxqVDEo"
      },
      "source": [
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGhHdcmHs3GD"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg3Ik1L6s8ex"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp4__S70zxAw"
      },
      "source": [
        "model-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdt3q-9Y5vNM",
        "outputId": "9904392d-0abf-497d-9c3d-f3eea7eaa07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data=(X_test,Y_test),  interval=1):\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "    self.losses = []\n",
        "    self.lr = []\n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "        y_pred_train = self.model.predict(self.X_val)\n",
        "        roc_train = roc_auc_score(self.y_val, y_pred_train)\n",
        "        y_pred_val = self.model.predict(self.X_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val)))\n",
        "        val_targ = self.y_val\n",
        "        val_predict=np.argmax(val_predict, axis=1)\n",
        "        val_targ=np.argmax(val_targ, axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average= 'micro')\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(scheduler(len(self.losses)))\n",
        "        print(\"\\rroc_auc-score: %s - f1-score: %s \" %(str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "\n",
        "\n",
        "import math\n",
        "def scheduler(epoch):\n",
        "  initial_lrate = 0.1\n",
        "  drop = 0.05\n",
        "  epochs_drop = 3.0\n",
        "  lrate = initial_lrate * math.pow(drop,\n",
        "  math.floor((1+epoch)/epochs_drop))\n",
        "  return lrate\n",
        "\n",
        "m1= keras.models.Sequential()\n",
        "m1.add(tf.keras.layers.Dense(units =50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1),input_shape=(784,)))\n",
        "m1.add(tf.keras.layers.Dense(units =50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m1.add(tf.keras.layers.Dense(units =50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m1.add(tf.keras.layers.Dense(units =50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m1.add(tf.keras.layers.Dense(units =50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m1.add(tf.keras.layers.Dense(units =10,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "\n",
        "history_own = Metrics()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0, patience=1, min_lr=0.1)\n",
        "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "callback12 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',  verbose=1,save_weights_only=False, save_best_only=False , mode='max')\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "\n",
        "m1.compile(optimizer=tf.keras.optimizers.SGD(0.1),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "m1.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=[history_own,reduce_lr,terminate,callback12,checkpoint,callback,tensorboard_callback ])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "roc_auc-score: 0.4987 - f1-score: 0.4987                                                                                                     \n",
            "\n",
            "Epoch 00001: saving model to weights-improvement-01-0.9000.hdf5\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.3263 - acc: 0.9000 - val_loss: 0.3252 - val_acc: 0.9000\n",
            "Epoch 2/5\n",
            "roc_auc-score: 0.5017 - f1-score: 0.5017                                                                                                     \n",
            "\n",
            "Epoch 00002: saving model to weights-improvement-02-0.9000.hdf5\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.3258 - acc: 0.9000 - val_loss: 0.3259 - val_acc: 0.9000\n",
            "Epoch 3/5\n",
            "roc_auc-score: 0.5002 - f1-score: 0.5002                                                                                                     \n",
            "\n",
            "Epoch 00003: saving model to weights-improvement-03-0.9000.hdf5\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.3250 - acc: 0.9000 - val_loss: 0.3249 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9ea1e61d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-1w1EINcX0I"
      },
      "source": [
        "!rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFABZKjFzu6E"
      },
      "source": [
        "model-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wzOUAtZWFpe",
        "outputId": "9fd759ab-1598-4630-b44f-07d454dbbae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data=(X_test,Y_test),  interval=1):\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "        y_pred_train = self.model.predict(self.X_val)\n",
        "        roc_train = roc_auc_score(self.y_val, y_pred_train)\n",
        "        y_pred_val = self.model.predict(self.X_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val)))\n",
        "        val_targ = self.y_val\n",
        "        val_predict=np.argmax(val_predict, axis=1)\n",
        "        val_targ=np.argmax(val_targ, axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average= 'micro')\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"\\rroc-auc_train: %s - roc-auc_val: %s \" %(str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "def scheduler(epoch,lr):\n",
        "   if(epoch%3==0):\n",
        "     lr *= 0.95\n",
        "   return lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m2= keras.models.Sequential()\n",
        "m2.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1),input_shape=(784,)))\n",
        "m2.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m2.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m2.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m2.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "m2.add(tf.keras.layers.Dense(units =10,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(0,1)))\n",
        "\n",
        "\n",
        "history_own = Metrics()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0, patience=1, min_lr=0.1)\n",
        "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "callback12 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',  verbose=1,save_weights_only=False, save_best_only=False , mode='max')\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "\n",
        "m2.compile(optimizer=tf.keras.optimizers.SGD(0.1),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "m2.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[history_own,reduce_lr,terminate,callback12,checkpoint,callback,tensorboard_callback2 ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00001: saving model to weights-improvement-01-0.8202.hdf5\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 2.7540 - acc: 0.8204 - val_loss: 2.7576 - val_acc: 0.8202\n",
            "Epoch 2/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00002: saving model to weights-improvement-02-0.8202.hdf5\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 2.7540 - acc: 0.8204 - val_loss: 2.7576 - val_acc: 0.8202\n",
            "Epoch 3/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00003: saving model to weights-improvement-03-0.8202.hdf5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 2.7540 - acc: 0.8204 - val_loss: 2.7576 - val_acc: 0.8202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9dda36f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avKIXak6efR"
      },
      "source": [
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTAbQLHzsWx"
      },
      "source": [
        "model-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5VNxE76j9x",
        "outputId": "713f885d-c386-421e-aef7-46cfa920b406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data=(X_test,Y_test),  interval=1):\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "        y_pred_train = self.model.predict(self.X_val)\n",
        "        roc_train = roc_auc_score(self.y_val, y_pred_train)\n",
        "        y_pred_val = self.model.predict(self.X_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val)))\n",
        "        val_targ = self.y_val\n",
        "        val_predict=np.argmax(val_predict, axis=1)\n",
        "        val_targ=np.argmax(val_targ, axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average= 'micro')\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"\\rroc-auc_train: %s - roc-auc_val: %s \" %(str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "def scheduler(epoch,lr):\n",
        "   if(epoch%3==0):\n",
        "     lr *= 0.95\n",
        "   return lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m3= keras.models.Sequential()\n",
        "m3.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform(),input_shape=(784,)))\n",
        "m3.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\n",
        "m3.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\n",
        "m3.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\n",
        "m3.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\n",
        "m3.add(tf.keras.layers.Dense(units =10,activation='softmax',kernel_initializer=tf.keras.initializers.he_uniform()))\n",
        "\n",
        "\n",
        "\n",
        "history_own = Metrics()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0, patience=1, min_lr=0.1)\n",
        "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "callback12 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',  verbose=1,save_weights_only=False, save_best_only=False , mode='max')\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback3 = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "\n",
        "m3.compile(optimizer=tf.keras.optimizers.SGD(0.1),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "m3.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[history_own,reduce_lr,terminate,callback12,checkpoint,callback,tensorboard_callback3])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00001: saving model to weights-improvement-01-0.8196.hdf5\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 2.7586 - acc: 0.8201 - val_loss: 2.7668 - val_acc: 0.8196\n",
            "Epoch 2/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00002: saving model to weights-improvement-02-0.8196.hdf5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 2.7646 - acc: 0.8197 - val_loss: 2.7668 - val_acc: 0.8196\n",
            "Epoch 3/3\n",
            "roc-auc_train: 0.5 - roc-auc_val: 0.5                                                                                                     \n",
            "\n",
            "Epoch 00003: saving model to weights-improvement-03-0.8196.hdf5\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 2.7646 - acc: 0.8197 - val_loss: 2.7668 - val_acc: 0.8196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9ddcfd320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNutnmwvzaAr"
      },
      "source": [
        "model-4:\n",
        "\n",
        "optimizer:adam,initializer:glorot_uniform()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJT5nZhdyIzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "422788a0-db10-4b6e-e6db-49b3761e208e"
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data=(X_test,Y_test),  interval=1):\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "        y_pred_train = self.model.predict(self.X_val)\n",
        "        roc_train = roc_auc_score(self.y_val, y_pred_train)\n",
        "        y_pred_val = self.model.predict(self.X_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val)))\n",
        "        val_targ = self.y_val\n",
        "        val_predict=np.argmax(val_predict, axis=1)\n",
        "        val_targ=np.argmax(val_targ, axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average= 'micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average= 'micro')\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"\\rroc-auc_train: %s -f1-score: %s\" %(str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "def scheduler(epoch,lr):\n",
        "   if(epoch%3==0):\n",
        "     lr *= 0.95\n",
        "   return lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m4= keras.models.Sequential()\n",
        "m4.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.glorot_uniform(),input_shape=(784,)))\n",
        "m4.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.glorot_uniform()))\n",
        "m4.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.glorot_uniform()))\n",
        "m4.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.glorot_uniform()))\n",
        "m4.add(tf.keras.layers.Dense(units =50,activation='relu',kernel_initializer=tf.keras.initializers.glorot_uniform()))\n",
        "m4.add(tf.keras.layers.Dense(units =10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_uniform()))\n",
        "\n",
        "\n",
        "\n",
        "history_own = Metrics()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0, patience=1, min_lr=0.1)\n",
        "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
        "callback12 = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc',  verbose=1,save_weights_only=False, save_best_only=False , mode='max')\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback4= tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "\n",
        "m4.compile(optimizer=tf.keras.optimizers.Adam(0.1),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "m4.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[history_own,reduce_lr,terminate,callback12,checkpoint,callback,tensorboard_callback4])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "roc-auc_train: 0.5 -f1-score: 0.5                                                                                                    \n",
            "\n",
            "Epoch 00001: saving model to weights-improvement-01-0.8192.hdf5\n",
            "60000/60000 [==============================] - 12s 195us/sample - loss: 2.7650 - acc: 0.8197 - val_loss: 2.7736 - val_acc: 0.8192\n",
            "Epoch 2/3\n",
            "roc-auc_train: 0.5 -f1-score: 0.5                                                                                                    \n",
            "\n",
            "Epoch 00002: saving model to weights-improvement-02-0.8192.hdf5\n",
            "60000/60000 [==============================] - 11s 184us/sample - loss: 2.7649 - acc: 0.8197 - val_loss: 2.7736 - val_acc: 0.8192\n",
            "Epoch 3/3\n",
            "roc-auc_train: 0.5 -f1-score: 0.5                                                                                                    \n",
            "\n",
            "Epoch 00003: saving model to weights-improvement-03-0.8192.hdf5\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 2.7649 - acc: 0.8197 - val_loss: 2.7736 - val_acc: 0.8192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9dd780160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}
